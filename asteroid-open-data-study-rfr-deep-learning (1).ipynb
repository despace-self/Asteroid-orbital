{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":840710,"sourceType":"datasetVersion","datasetId":408523}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfile_path = '/kaggle/input/prediction-of-asteroid-diameter/Asteroid.csv'\ndata = pd.read_csv(file_path)\ndata.head()\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:51:16.449652Z","iopub.execute_input":"2024-12-29T05:51:16.450086Z","iopub.status.idle":"2024-12-29T05:51:21.405661Z","shell.execute_reply.started":"2024-12-29T05:51:16.450052Z","shell.execute_reply":"2024-12-29T05:51:21.404553Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/prediction-of-asteroid-diameter/Asteroid_Updated.csv\n/kaggle/input/prediction-of-asteroid-diameter/Asteroid.csv\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"        full_name         a         e     G          i          om  \\\n0         1 Ceres  2.769165  0.076009  0.12  10.594067   80.305532   \n1        2 Pallas  2.772466  0.230337  0.11  34.836234  173.080063   \n2          3 Juno  2.669150  0.256942  0.32  12.988919  169.852760   \n3         4 Vesta  2.361418  0.088721  0.32   7.141771  103.810804   \n4       5 Astraea  2.574249  0.191095   NaN   5.366988  141.576604   \n\n            w         q        ad     per_y  ...    rot_per       GM     BV  \\\n0   73.597694  2.558684  2.979647  4.608202  ...   9.074170  62.6284  0.713   \n1  310.048857  2.133865  3.411067  4.616444  ...   7.813200  14.3000  0.635   \n2  248.138626  1.983332  3.354967  4.360814  ...   7.210000      NaN  0.824   \n3  150.728541  2.151909  2.570926  3.628837  ...   5.342128  17.8000  0.782   \n4  358.687608  2.082324  3.066174  4.130323  ...  16.806000      NaN  0.826   \n\n      UB  IR spec_B  spec_T  neo  pha     moid  \n0  0.426 NaN      C       G    N    N  1.59478  \n1  0.284 NaN      B       B    N    N  1.23324  \n2  0.433 NaN     Sk       S    N    N  1.03454  \n3  0.492 NaN      V       V    N    N  1.13948  \n4  0.411 NaN      S       S    N    N  1.09589  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_name</th>\n      <th>a</th>\n      <th>e</th>\n      <th>G</th>\n      <th>i</th>\n      <th>om</th>\n      <th>w</th>\n      <th>q</th>\n      <th>ad</th>\n      <th>per_y</th>\n      <th>...</th>\n      <th>rot_per</th>\n      <th>GM</th>\n      <th>BV</th>\n      <th>UB</th>\n      <th>IR</th>\n      <th>spec_B</th>\n      <th>spec_T</th>\n      <th>neo</th>\n      <th>pha</th>\n      <th>moid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1 Ceres</td>\n      <td>2.769165</td>\n      <td>0.076009</td>\n      <td>0.12</td>\n      <td>10.594067</td>\n      <td>80.305532</td>\n      <td>73.597694</td>\n      <td>2.558684</td>\n      <td>2.979647</td>\n      <td>4.608202</td>\n      <td>...</td>\n      <td>9.074170</td>\n      <td>62.6284</td>\n      <td>0.713</td>\n      <td>0.426</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>G</td>\n      <td>N</td>\n      <td>N</td>\n      <td>1.59478</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2 Pallas</td>\n      <td>2.772466</td>\n      <td>0.230337</td>\n      <td>0.11</td>\n      <td>34.836234</td>\n      <td>173.080063</td>\n      <td>310.048857</td>\n      <td>2.133865</td>\n      <td>3.411067</td>\n      <td>4.616444</td>\n      <td>...</td>\n      <td>7.813200</td>\n      <td>14.3000</td>\n      <td>0.635</td>\n      <td>0.284</td>\n      <td>NaN</td>\n      <td>B</td>\n      <td>B</td>\n      <td>N</td>\n      <td>N</td>\n      <td>1.23324</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3 Juno</td>\n      <td>2.669150</td>\n      <td>0.256942</td>\n      <td>0.32</td>\n      <td>12.988919</td>\n      <td>169.852760</td>\n      <td>248.138626</td>\n      <td>1.983332</td>\n      <td>3.354967</td>\n      <td>4.360814</td>\n      <td>...</td>\n      <td>7.210000</td>\n      <td>NaN</td>\n      <td>0.824</td>\n      <td>0.433</td>\n      <td>NaN</td>\n      <td>Sk</td>\n      <td>S</td>\n      <td>N</td>\n      <td>N</td>\n      <td>1.03454</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4 Vesta</td>\n      <td>2.361418</td>\n      <td>0.088721</td>\n      <td>0.32</td>\n      <td>7.141771</td>\n      <td>103.810804</td>\n      <td>150.728541</td>\n      <td>2.151909</td>\n      <td>2.570926</td>\n      <td>3.628837</td>\n      <td>...</td>\n      <td>5.342128</td>\n      <td>17.8000</td>\n      <td>0.782</td>\n      <td>0.492</td>\n      <td>NaN</td>\n      <td>V</td>\n      <td>V</td>\n      <td>N</td>\n      <td>N</td>\n      <td>1.13948</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5 Astraea</td>\n      <td>2.574249</td>\n      <td>0.191095</td>\n      <td>NaN</td>\n      <td>5.366988</td>\n      <td>141.576604</td>\n      <td>358.687608</td>\n      <td>2.082324</td>\n      <td>3.066174</td>\n      <td>4.130323</td>\n      <td>...</td>\n      <td>16.806000</td>\n      <td>NaN</td>\n      <td>0.826</td>\n      <td>0.411</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>S</td>\n      <td>N</td>\n      <td>N</td>\n      <td>1.09589</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 27 columns</p>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"#the orbital period of asteroids (per year) will be predicted in this model.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Data Preprocessing\nmissing_value_count_by_column = (data.isnull().sum())\nprint(missing_value_count_by_column[missing_value_count_by_column > 0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:51:27.302348Z","iopub.execute_input":"2024-12-29T05:51:27.302725Z","iopub.status.idle":"2024-12-29T05:51:27.570912Z","shell.execute_reply.started":"2024-12-29T05:51:27.302695Z","shell.execute_reply":"2024-12-29T05:51:27.569701Z"}},"outputs":[{"name":"stdout","text":"a                      2\nG                 839617\nad                     6\nper_y                  1\ndata_arc           15789\ncondition_code       993\nH                   2694\ndiameter          702055\nextent            839718\nalbedo            703284\nrot_per           820940\nGM                839722\nBV                838715\nUB                838757\nIR                839735\nspec_B            838070\nspec_T            838756\nneo                    6\npha                16922\nmoid               16922\ndtype: int64\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"'''It can be observed that the columns G, diameter,extent,albedo,rot_per,\nGM,BV,UB,IR, spec_B, spec_T wont be any help to the model training process\nthose columns can be dropped initially.\n\nNext data_arc, pha, moid columns could be of use if used imputation\n\nalso codition_code, H and\n\nlastly least data missing columns a, ad, neo also the same method'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#drop unusable columns\ncolumns_to_drop = ['G','diameter','extent','albedo','rot_per','GM','BV','UB','IR','spec_B','spec_T']\ndata.drop(columns=columns_to_drop, inplace=True)\nprint(data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:51:37.210002Z","iopub.execute_input":"2024-12-29T05:51:37.210429Z","iopub.status.idle":"2024-12-29T05:51:37.269647Z","shell.execute_reply.started":"2024-12-29T05:51:37.210393Z","shell.execute_reply":"2024-12-29T05:51:37.268355Z"}},"outputs":[{"name":"stdout","text":"        full_name         a         e          i          om           w  \\\n0         1 Ceres  2.769165  0.076009  10.594067   80.305532   73.597694   \n1        2 Pallas  2.772466  0.230337  34.836234  173.080063  310.048857   \n2          3 Juno  2.669150  0.256942  12.988919  169.852760  248.138626   \n3         4 Vesta  2.361418  0.088721   7.141771  103.810804  150.728541   \n4       5 Astraea  2.574249  0.191095   5.366988  141.576604  358.687608   \n\n          q        ad     per_y  data_arc condition_code  n_obs_used     H  \\\n0  2.558684  2.979647  4.608202    8822.0              0        1002  3.34   \n1  2.133865  3.411067  4.616444   72318.0              0        8490  4.13   \n2  1.983332  3.354967  4.360814   72684.0              0        7104  5.33   \n3  2.151909  2.570926  3.628837   24288.0              0        9325  3.20   \n4  2.082324  3.066174  4.130323   63431.0              0        2861  6.85   \n\n  neo pha     moid  \n0   N   N  1.59478  \n1   N   N  1.23324  \n2   N   N  1.03454  \n3   N   N  1.13948  \n4   N   N  1.09589  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#find categorical variables\ns = (data.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:51:40.650317Z","iopub.execute_input":"2024-12-29T05:51:40.650705Z","iopub.status.idle":"2024-12-29T05:51:40.657922Z","shell.execute_reply.started":"2024-12-29T05:51:40.650677Z","shell.execute_reply":"2024-12-29T05:51:40.656388Z"}},"outputs":[{"name":"stdout","text":"Categorical variables:\n['full_name', 'condition_code', 'neo', 'pha']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#check to see the unique values\nunique_count_neo = data['neo'].unique()\nunique_count_pha = data['pha'].unique()\nunique_count_codition_code = data['condition_code'].unique()\nprint(f\"Unique count neo: {unique_count_neo}\")\nprint(f\"Unique count pha: {unique_count_pha}\")\nprint(f\"Unique count condition_code: {unique_count_codition_code}\")\nprint(data['condition_code'].dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:51:43.656614Z","iopub.execute_input":"2024-12-29T05:51:43.657017Z","iopub.status.idle":"2024-12-29T05:51:43.743838Z","shell.execute_reply.started":"2024-12-29T05:51:43.656985Z","shell.execute_reply":"2024-12-29T05:51:43.742289Z"}},"outputs":[{"name":"stdout","text":"Unique count neo: ['N' 'Y' nan]\nUnique count pha: ['N' 'Y' nan]\nUnique count condition_code: [0 2 1 4 3 5 nan '0' '1' '2' '3' '4' '8' '9' '7' '6' '5' 'E' 9.0 7.0 6.0\n 8.0 'D']\nobject\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#the condition_code column contains multiple data types.\n#this process will seperate the condition_code column into 2 columns according to dtype\n\nstring_count = data['condition_code'].dropna().apply(lambda x: isinstance(x, str)).sum()\nnumeric_count = data['condition_code'].dropna().apply(lambda x: isinstance(x, (int, float))).sum()\nprint(f\"Number of Strings: {string_count}\")\nprint(f\"Number count: {numeric_count}\")\n\ndata['condition_code_str'] = data['condition_code'].apply(lambda x: x if isinstance(x, str) else None)\ndata['condition_code_num'] = data['condition_code'].apply(lambda x: x if isinstance(x, (int,float)) else None)\n\ncolumns_to_drop = ['condition_code', 'full_name']\ndata.drop(columns=columns_to_drop, inplace=True)\n\nprint(data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:51:47.936099Z","iopub.execute_input":"2024-12-29T05:51:47.936474Z","iopub.status.idle":"2024-12-29T05:51:48.948330Z","shell.execute_reply.started":"2024-12-29T05:51:47.936446Z","shell.execute_reply":"2024-12-29T05:51:48.947111Z"}},"outputs":[{"name":"stdout","text":"Number of Strings: 248940\nNumber count: 589803\n          a         e          i          om           w         q        ad  \\\n0  2.769165  0.076009  10.594067   80.305532   73.597694  2.558684  2.979647   \n1  2.772466  0.230337  34.836234  173.080063  310.048857  2.133865  3.411067   \n2  2.669150  0.256942  12.988919  169.852760  248.138626  1.983332  3.354967   \n3  2.361418  0.088721   7.141771  103.810804  150.728541  2.151909  2.570926   \n4  2.574249  0.191095   5.366988  141.576604  358.687608  2.082324  3.066174   \n\n      per_y  data_arc  n_obs_used     H neo pha     moid condition_code_str  \\\n0  4.608202    8822.0        1002  3.34   N   N  1.59478               None   \n1  4.616444   72318.0        8490  4.13   N   N  1.23324               None   \n2  4.360814   72684.0        7104  5.33   N   N  1.03454               None   \n3  3.628837   24288.0        9325  3.20   N   N  1.13948               None   \n4  4.130323   63431.0        2861  6.85   N   N  1.09589               None   \n\n   condition_code_num  \n0                 0.0  \n1                 0.0  \n2                 0.0  \n3                 0.0  \n4                 0.0  \n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#creating backup\nbackup_data = data.copy()\n\n#oridinal encoding will be applied to 'neo' and 'pha' columns\nfrom sklearn.preprocessing import OrdinalEncoder\n\nordinal_encoder = OrdinalEncoder()\ncolumns_to_encode = ['neo', 'pha', 'condition_code_str', 'condition_code_num']\nfor col in columns_to_encode:\n    data[col] = ordinal_encoder.fit_transform(data[col].values.reshape(-1,1))\n\nprint(data[columns_to_encode].head())\nprint(data.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:51:54.879833Z","iopub.execute_input":"2024-12-29T05:51:54.880198Z","iopub.status.idle":"2024-12-29T05:51:56.104583Z","shell.execute_reply.started":"2024-12-29T05:51:54.880171Z","shell.execute_reply":"2024-12-29T05:51:56.103425Z"}},"outputs":[{"name":"stdout","text":"   neo  pha  condition_code_str  condition_code_num\n0  0.0  0.0                12.0                 0.0\n1  0.0  0.0                12.0                 0.0\n2  0.0  0.0                12.0                 0.0\n3  0.0  0.0                12.0                 0.0\n4  0.0  0.0                12.0                 0.0\n          a         e          i          om           w         q        ad  \\\n0  2.769165  0.076009  10.594067   80.305532   73.597694  2.558684  2.979647   \n1  2.772466  0.230337  34.836234  173.080063  310.048857  2.133865  3.411067   \n2  2.669150  0.256942  12.988919  169.852760  248.138626  1.983332  3.354967   \n3  2.361418  0.088721   7.141771  103.810804  150.728541  2.151909  2.570926   \n4  2.574249  0.191095   5.366988  141.576604  358.687608  2.082324  3.066174   \n\n      per_y  data_arc  n_obs_used     H  neo  pha     moid  \\\n0  4.608202    8822.0        1002  3.34  0.0  0.0  1.59478   \n1  4.616444   72318.0        8490  4.13  0.0  0.0  1.23324   \n2  4.360814   72684.0        7104  5.33  0.0  0.0  1.03454   \n3  3.628837   24288.0        9325  3.20  0.0  0.0  1.13948   \n4  4.130323   63431.0        2861  6.85  0.0  0.0  1.09589   \n\n   condition_code_str  condition_code_num  \n0                12.0                 0.0  \n1                12.0                 0.0  \n2                12.0                 0.0  \n3                12.0                 0.0  \n4                12.0                 0.0  \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#Now a secondary check to see missing values\nmissing_value_count_by_column = (data.isnull().sum())\nprint(missing_value_count_by_column[missing_value_count_by_column > 0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:52:01.215017Z","iopub.execute_input":"2024-12-29T05:52:01.215576Z","iopub.status.idle":"2024-12-29T05:52:01.244361Z","shell.execute_reply.started":"2024-12-29T05:52:01.215542Z","shell.execute_reply":"2024-12-29T05:52:01.242947Z"}},"outputs":[{"name":"stdout","text":"a                          2\nad                         6\nper_y                      1\ndata_arc               15789\nH                       2694\nneo                        6\npha                    16922\nmoid                   16922\ncondition_code_num    249933\ndtype: int64\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#applying imputation for columns\nfrom sklearn.impute import SimpleImputer\nmy_imputer = SimpleImputer()\ncolumns_with_missing_values = ['a', 'ad', 'per_y', 'data_arc', 'H', 'moid', 'condition_code_num', 'neo', 'pha']\nnumeric_imputer = SimpleImputer(strategy='mean')\n\ndata[columns_with_missing_values]=numeric_imputer.fit_transform(data[columns_with_missing_values])\n\nprint(data.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:52:04.856422Z","iopub.execute_input":"2024-12-29T05:52:04.856785Z","iopub.status.idle":"2024-12-29T05:52:05.195843Z","shell.execute_reply.started":"2024-12-29T05:52:04.856753Z","shell.execute_reply":"2024-12-29T05:52:05.194604Z"}},"outputs":[{"name":"stdout","text":"          a         e          i          om           w         q        ad  \\\n0  2.769165  0.076009  10.594067   80.305532   73.597694  2.558684  2.979647   \n1  2.772466  0.230337  34.836234  173.080063  310.048857  2.133865  3.411067   \n2  2.669150  0.256942  12.988919  169.852760  248.138626  1.983332  3.354967   \n3  2.361418  0.088721   7.141771  103.810804  150.728541  2.151909  2.570926   \n4  2.574249  0.191095   5.366988  141.576604  358.687608  2.082324  3.066174   \n\n      per_y  data_arc  n_obs_used     H  neo  pha     moid  \\\n0  4.608202    8822.0        1002  3.34  0.0  0.0  1.59478   \n1  4.616444   72318.0        8490  4.13  0.0  0.0  1.23324   \n2  4.360814   72684.0        7104  5.33  0.0  0.0  1.03454   \n3  3.628837   24288.0        9325  3.20  0.0  0.0  1.13948   \n4  4.130323   63431.0        2861  6.85  0.0  0.0  1.09589   \n\n   condition_code_str  condition_code_num  \n0                12.0                 0.0  \n1                12.0                 0.0  \n2                12.0                 0.0  \n3                12.0                 0.0  \n4                12.0                 0.0  \n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#final check for missing values\nmissing_values = data.isnull().sum()\nprint(missing_values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:52:08.650210Z","iopub.execute_input":"2024-12-29T05:52:08.650689Z","iopub.status.idle":"2024-12-29T05:52:08.680438Z","shell.execute_reply.started":"2024-12-29T05:52:08.650654Z","shell.execute_reply":"2024-12-29T05:52:08.679164Z"}},"outputs":[{"name":"stdout","text":"a                     0\ne                     0\ni                     0\nom                    0\nw                     0\nq                     0\nad                    0\nper_y                 0\ndata_arc              0\nn_obs_used            0\nH                     0\nneo                   0\npha                   0\nmoid                  0\ncondition_code_str    0\ncondition_code_num    0\ndtype: int64\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#split the dataset into training set and validation set.\nfrom sklearn.model_selection import train_test_split\n\n#define the target variable\ny = data['per_y']\nX = data.drop(columns=['per_y'])\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T09:59:37.139184Z","iopub.execute_input":"2024-12-29T09:59:37.139622Z","iopub.status.idle":"2024-12-29T09:59:37.603229Z","shell.execute_reply.started":"2024-12-29T09:59:37.139581Z","shell.execute_reply":"2024-12-29T09:59:37.602313Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"# Select the relevant features (inputs) and the target variable\nX_train_selected = X_train[['A', 'ad', 'data_arc', 'q', 'moid']]\nX_valid_selected = X_valid[['A', 'ad', 'data_arc', 'q', 'moid']]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T05:52:20.041872Z","iopub.execute_input":"2024-12-29T05:52:20.042273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Initialize the scaler\nscaler = StandardScaler()\n\n# Fit and transform on the training data, then transform the test data\nX_train_scaled = scaler.fit_transform(X_train_selected)\nX_valid_scaled = scaler.transform(X_valid_selected)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T10:07:09.459920Z","iopub.execute_input":"2024-12-29T10:07:09.460403Z","iopub.status.idle":"2024-12-29T10:07:09.580604Z","shell.execute_reply.started":"2024-12-29T10:07:09.460368Z","shell.execute_reply":"2024-12-29T10:07:09.579389Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler\n\n# Step 1: Select only 'A' as the input feature\nX_train_a = X_train_selected\nX_valid_a = X_valid_selected\n\n# Step 2: Optional - Scale the feature\nscaler = StandardScaler()\nX_train_a_scaled = scaler.fit_transform(X_train_a)\nX_valid_a_scaled = scaler.transform(X_valid_a)\n\n# Step 3: Train the Random Forest Regressor\nrf_model = RandomForestRegressor(n_estimators=150, random_state=42)  # You can tune the number of trees (n_estimators)\nrf_model.fit(X_train_a_scaled, y_train)\n\n# Step 4: Make predictions\ny_pred_rf = rf_model.predict(X_test_a_scaled)\n\n# Step 5: Evaluate the model\nmse_rf = mean_squared_error(y_valid, y_pred_rf)\nr2_rf = r2_score(y_valid, y_pred_rf)\n\nprint(f\"Random Forest Regression - Mean Squared Error: {mse_rf}\")\nprint(f\"Random Forest Regression - RÂ² Score: {r2_rf}\")\n\n# Optional: Feature importance (to see how 'A' contributes to the model)\nprint(\"Feature Importances: \", rf_model.feature_importances_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T10:07:50.299469Z","iopub.execute_input":"2024-12-29T10:07:50.299882Z","iopub.status.idle":"2024-12-29T10:07:57.481979Z","shell.execute_reply.started":"2024-12-29T10:07:50.299851Z","shell.execute_reply":"2024-12-29T10:07:57.480035Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-87-415dc799ff24>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Step 3: Train the Random Forest Regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mrf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# You can tune the number of trees (n_estimators)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_a_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Step 4: Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":87},{"cell_type":"code","source":"# Fit a polynomial of degree 2 (quadratic) to the data\ncoeffs = np.polyfit(y_valid, y_pred, 2)  # Change 2 to a higher degree for a more flexible curve\npoly_eq = np.poly1d(coeffs)\n\n# Create points to plot the curve\nx_vals = np.linspace(y_valid.min(), y_valid.max(), 100)\ny_vals = poly_eq(x_vals)\n\n# Scatter plot of Actual vs Predicted\nplt.figure(figsize=(8, 6))\nplt.scatter(y_valid, y_pred, color='blue', label='Actual vs Predicted')\n\n# Plot the polynomial fit curve\nplt.plot(x_vals, y_vals, color='red', linewidth=2, label='Fitted Curve')\nplt.title('Actual vs Predicted with Polynomial Fit')\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n# Feature Importance Plot\nfeatures = ['ad', 'data_arc', 'q', 'moid', 'full_name']  # Replace this list with the actual feature names\nimportances = [0.5184, 0.4735, 0.0033, 0.0022, 0.0026]  # Use the actual feature importances from the model\nindices = np.argsort(importances)\n\nplt.figure(figsize=(8, 6))\nplt.barh(np.array(features)[indices], np.array(importances)[indices], color='green')\nplt.title('Feature Importances')\nplt.xlabel('Importance')\nplt.ylabel('Feature')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}